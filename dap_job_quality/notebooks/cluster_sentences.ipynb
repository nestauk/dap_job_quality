{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While labelling data, I noticed that there is often overlap between how the CIPD 7 dimensions are expressed in job ads. For example, a sentence like \"You will be supported to grow in your career\" could indicate \"job design and nature of work\" (because it is about career progression), or it could indicate \"social support and cohesion\" (because it suggests a supportive work environment). To investigate this further, I decided to try clustering the sentences in the job ads using a word embedding model, and then see if the clusters corresponded to the CIPD 7 dimensions or if there were other patterns that we could potentially use.\n",
    "\n",
    "The approach here is:\n",
    "- pull out the labelled spans\n",
    "- extract the entire sentence (as captured with spaCy's `sent` attribute) in which the span occurs\n",
    "- embed the sentence using a pre-trained word embedding model `all-MiniLM-L6-v2`\n",
    "- cluster the embeddings using kmeans\n",
    "- dimensionality reduction using t-SNE\n",
    "- visualise the embeddings, first with the original labels of the sentences and then with the kmeans clusters\n",
    "\n",
    "At the moment I'm not really sure how useful this is or what conclusions we could draw. Might be more helpful to use BERTopic and try to get meaningful summaries of the clusters.\n",
    "\n",
    "It's also just a very tiny sample of the data, which is another reason why it's hard to draw any conclusions from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from spacy.tokens import Span\n",
    "import spacy\n",
    "import srsly\n",
    "\n",
    "from dap_job_quality import PROJECT_DIR, BUCKET_NAME, logger\n",
    "import dap_job_quality.utils.prodigy_data_utils as pdu\n",
    "from dap_job_quality.getters.data_getters import load_s3_jsonl\n",
    "\n",
    "# models that we'll use\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file1 = 'outputs/prodigy/labelled_data/20240119_ads_labelled_rosie_downloaded.jsonl'\n",
    "local_file2 = 'outputs/prodigy/labelled_data/20240123_ads_labelled_rosie_downloaded.jsonl'\n",
    "\n",
    "_ = load_s3_jsonl(BUCKET_NAME, 'job_quality/prodigy/labelled_data/20240119_ads_labelled_rosie.jsonl', local_file1)\n",
    "_ = load_s3_jsonl(BUCKET_NAME, 'job_quality/prodigy/labelled_data/20240123_ads_labelled_rosie.jsonl', local_file2)\n",
    "\n",
    "all_records = []\n",
    "\n",
    "for file in [local_file1, local_file2]:\n",
    "    records = pdu.read_accepted_lines(file)\n",
    "    for record in records:\n",
    "        all_records.append(record)\n",
    "        \n",
    "all_records_deduplicated = []\n",
    "seen_job_ids = set()\n",
    "\n",
    "for item in all_records:\n",
    "    job_id = item['meta']['job_id']\n",
    "    if job_id not in seen_job_ids:\n",
    "        seen_job_ids.add(job_id)\n",
    "        all_records_deduplicated.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_records) - len(all_records_deduplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pdu.get_spans_and_sentences(all_records_deduplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data = []\n",
    "for job_id, entries in training_data.items():\n",
    "    for entry in entries:\n",
    "        flat_data.append({\n",
    "            \"job_id\": job_id,\n",
    "            \"labelled_span\": entry[\"span\"],\n",
    "            \"full_sentence\": entry[\"sent\"],\n",
    "            \"label\": entry[\"label\"],\n",
    "            \"text\": entry[\"text\"]\n",
    "        })\n",
    "\n",
    "labelled_spans_df = pd.DataFrame(flat_data)\n",
    "\n",
    "labelled_spans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_spans_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decided to label the 'benefit' category in there because it will be quite different from the other categories, so might\n",
    "# shed light on to what extent the other categories overlap\n",
    "clustering_df = labelled_spans_df[(labelled_spans_df['label'] != 'none')][['label', 'full_sentence', 'labelled_span']]\n",
    "clustering_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(clustering_df['full_sentence'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10 #int(len(embeddings) ** 0.5)\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "clusters = kmeans.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the cluster names back into the dataframe\n",
    "clustering_df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to 2d for visualisation\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with original labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label in clustering_df['label'].unique():\n",
    "    indices = clustering_df['label'] == label\n",
    "    plt.scatter(embeddings_2d[indices, 0], embeddings_2d[indices, 1], label=label)\n",
    "plt.legend()\n",
    "plt.title(\"Clusters with Original Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with cluster labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster in range(num_clusters):\n",
    "    indices = clusters == cluster\n",
    "    plt.scatter(embeddings_2d[indices, 0], embeddings_2d[indices, 1], label=f\"Cluster {cluster}\")\n",
    "plt.legend()\n",
    "plt.title(\"Clusters with Cluster Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dap_job_quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
