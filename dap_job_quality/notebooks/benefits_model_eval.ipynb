{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import srsly\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from dap_job_quality import PROJECT_DIR, BUCKET_NAME\n",
    "from dap_job_quality.getters.data_getters import load_s3_jsonl\n",
    "import dap_job_quality.utils.prodigy_data_utils as pdu\n",
    "import dap_job_quality.utils.eda_utils as eda\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other helper functions\n",
    "def tokenize(text, n=2):\n",
    "    \"\"\"Tokenize text into n-grams\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]  # Remove non-alphabetic tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "def most_common_ngrams(df, n=2, label_col='label', text_col='labelled_span', n_most_common=10):\n",
    "    \"\"\"Find the most common n-grams within a category\n",
    "    \"\"\"\n",
    "    category_ngrams = {}\n",
    "    for category in df[label_col].unique():\n",
    "        ngrams_list = []\n",
    "        for text in df[df[label_col] == category][text_col]:\n",
    "            n_grams = tokenize(text, n)\n",
    "            ngrams_list.extend(n_grams)\n",
    "        category_ngrams[category] = Counter(ngrams_list).most_common(n_most_common)\n",
    "    return category_ngrams\n",
    "\n",
    "def find_phrase_and_sentence(text, phrases):\n",
    "    \"\"\"Find a phrase in a text and return the whole sentence containing the phrase\n",
    "    \"\"\"\n",
    "    for phrase in phrases:\n",
    "        if phrase in text.lower():  # Check if the phrase is in the text\n",
    "            # Find the whole sentence containing the phrase\n",
    "            sentence = re.search(r'([^.]*?'+re.escape(phrase)+r'[^.]*\\.)', text, re.IGNORECASE)\n",
    "            if sentence:\n",
    "                return True, sentence.group()\n",
    "    return False, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file1 = PROJECT_DIR / 'dap_job_quality/pipeline/prodigy/labelled_data/benefits_model_eval.jsonl'\n",
    "\n",
    "_ = load_s3_jsonl(BUCKET_NAME, 'job_quality/prodigy/labelled_data/benefits_model_eval.jsonl', local_file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = []\n",
    "\n",
    "for file in [local_file1]:\n",
    "    records = []\n",
    "    for line in srsly.read_jsonl(file):\n",
    "        records.append(line)\n",
    "    for record in records:\n",
    "        all_records.append(record)\n",
    "        \n",
    "all_records_deduplicated = []\n",
    "seen_job_ids = set()\n",
    "\n",
    "for item in all_records:\n",
    "    job_id = item['meta']['job_id']\n",
    "    if job_id not in seen_job_ids:\n",
    "        seen_job_ids.add(job_id)\n",
    "        all_records_deduplicated.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = pd.DataFrame(all_records_deduplicated)\n",
    "all_records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records[all_records['answer']!='accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_spans = pdu.get_spans_and_sentences(all_records[all_records['answer']!='accept'].to_dict(orient='records'))\n",
    "rejected_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the number of rejected records as being false positives. This is actually not quite right - there are some spans in other job ads that were not quite right but that I did not bother correcting. So if anything, this underestimates the number of false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = len(rejected_spans)\n",
    "print(f\"Number of false positives: {false_positives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_spans = pdu.get_spans_and_sentences(all_records_deduplicated)\n",
    "accepted_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data = []\n",
    "for job_id, entries in accepted_spans.items():\n",
    "    for entry in entries:\n",
    "        flat_data.append({\n",
    "            \"job_id\": job_id,\n",
    "            \"labelled_span\": entry[\"span\"],\n",
    "            \"full_sentence\": entry[\"sent\"],\n",
    "            \"label\": entry[\"label\"],\n",
    "            \"text\": entry[\"text\"]\n",
    "        })\n",
    "\n",
    "labelled_spans_df = pd.DataFrame(flat_data)\n",
    "\n",
    "labelled_spans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefit_labels_count = pd.DataFrame(labelled_spans_df['label'].value_counts()).reset_index()\n",
    "benefit_labels_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define\n",
    "- true positives = the times when the BENEFIT entity was correct\n",
    "- false negatives = spans that a human (RO) tagged as being 'other_benefits', but the BENEFIT entity did not capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = benefit_labels_count[benefit_labels_count['label']=='benefit']['count'].values[0]\n",
    "false_negatives = benefit_labels_count[benefit_labels_count['label']=='other_benefits']['count'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labelled_spans_df['job_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = true_positives/(true_positives+false_positives)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = true_positives/(true_positives+false_negatives)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure the wordclouds tell us very much because it was such a small sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_categories = labelled_spans_df['label'].unique()\n",
    "label_categories = label_categories[(label_categories != 'none')]\n",
    "\n",
    "output_dir = PROJECT_DIR / 'outputs/figures/wordclouds_benefits.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud for each label\n",
    "eda.make_wordclouds(labelled_spans_df, label_categories, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dap_job_quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
